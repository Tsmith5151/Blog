---
layout: null
section-type: project
title: Projects
---

## Projects

<h3>
	<li>
	<a href = "https://github.com/Tsmith5151/Boston-Housing-Prices">
	<strong>Predict Boston Housing Prices</strong>
	</a></li></h3>
<p>
 This project applies basic machine learning concepts on data collected for housing prices in the Boston, Massachusetts area to predict the selling price of a new home. The first half of this work is directed towards exloring the data to obtain important features and descriptive statistics about the dataset. Next, the data is split into the testing and training subsets. From here, the appropriate performance metric is examined: Mean Squared Error or Mean Absotule Error. Performance graphs are generated for a learning algorithm with varying parameters and training set sizes. Analyzing these results enables the optimal model that best generalizes for unseen data to be selected. Using this optimal model, given a new sample (i.e. testing subset) the housing price is predictied and then compared to a series of descriptive statistics.


</p>

<h3>
	<li>
	<a href = "https://github.com/Tsmith5151/Student-Intervention">
	<strong>Student Intervention</strong>
	</a></li></h3>
<p>
The student intervention project analyzes a given dataset on students' performance and develops a machine learning model that will predict the likelihood that a given student will pass, quantifying whether an intervention is necessary. Various algorithms, such as Random Forest, Support Vector Machines, and Naive Bayes will be compared from the standpoint of complexity, runtime, and performance. Given the unbalance in class labels, the F1 score will be utilized as the performance metric. In other words, how well does the model differentiate likely passes from failures.
</p>


<h3>
	<li><a href = "https://github.com/Tsmith5151/Customer-Segments">
	<strong>Customer Segments</strong>
	</a></li></h3>
<p>
In this work, we will take unstructured data, and then attempt to understand the patterns and natural categories that the data fits into. The objective is to analyze this dataset containing data on various customers' annual spending amounts of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.
</p>

<h3>
	<li><a href = "https://github.com/Tsmith5151/Smartcab">
	<strong>Train Smartcab to Drive</strong>
	</a></li></h3>
<p>
Using reinforcement learning to train a smartcab how to drive by implementing Bellman's Q-learning algorithm.
</p>

<h3>
	<li><a href = "https://github.com/Tsmith5151/2016-US-Election-ML">
	<strong>Predicting Primary Winner for POTUS</strong>
	</a></li></h3>
<p>
The objective of this work is to leverage machine-learning techniques (i.e. Decision Trees and Random Forest) to predict whom voters are most likely to elect as the partyâ€™s nominee in 2016 Primary Election based on a series of demographics. A large database containing election results for both Democrat and Republican candidates from 28 primary state counties was queried and merged with demographic facts obtained from the United States Census Bureau for corresponding counties. This work examines patterns and trends in how voters cast their ballot given a larger feature space of county demographics spread throughout the United States. In some cases, some states are called with no actual votes tallied. This can come from models, similar to this work, where county-by-county demographics are analyzed for voting trends. The objective is to generate a predictive model and fine tune it such that the algorithm learns from a series of training examples and generalizes to an out of sample testing set that correctly classifies a discrete label, the candidate winner of the respected primary county. 
</p>

<h3>
	<li><a href = "https://github.com/Tsmith5151/Delayed-Flights">
	<strong>Delayed Flights</strong>
	</a></li></h3>
<p>
Exploring and predicting the probability of flights being delayed at airports across the United States given prior flight records. Apache Spark is used in processing the dataset.
</p>

### ***M.S. Research Project***

***Reasearch paper:<a href="/assets/Trace_Smith_MS_Research.pdf"> Download Here</a>***

My research focused on evaluating reservoir performance of hydraulic fractured wells in the ultra-tight shale reservoirs through production history matching utilizing numerical reservoir simulation. Fracture azimuth and lengths created through stimulation can be determined from microseismic data and through industry software programs given the hydraulic fracture design parameters such as volume pumped, proppant, and pressure; however, this data is not always readily available. Therefore, goal of history matching is to verify the accuracy of the model such that it behaves in such a way that resembles the actual field data (i.e. Pressure distribution, oil/gas production rates). The calibrated reservoir models for hydraulically fractured wells provide a proxy for estimating fracture attributes such as length, width, permeability, and porosity in these tight-shale reservoirs.






