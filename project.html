---
layout: null
section-type: project
title: Projects
---

## Projects

<h3>
	<li>
	<a href = "https://github.com/Tsmith5151/Boston-Housing-Prices">
	<strong>Predict Boston Housing Prices</strong>
	</a></li></h3>
<p>
 This project applies basic machine learning concepts on data collected for housing prices in the Boston, Massachusetts area to predict the selling price of a new home. The first half of this work is directed towards exloring the data to obtain important features and descriptive statistics about the dataset. Next, the data is split into the testing and training subsets. From here, the appropriate performance metric is examined: Mean Squared Error or Mean Absotule Error. Performance graphs are generated for a learning algorithm with varying parameters and training set sizes. Analyzing these results enables the optimal model that best generalizes for unseen data to be selected. Using this optimal model, given a new sample (i.e. testing subset) the housing price is predictied and then compared to a series of descriptive statistics.


</p>

<h3>
	<li>
	<a href = "https://github.com/Tsmith5151/Student-Intervention">
	<strong>Student Intervention</strong>
	</a></li></h3>
<p>
The student intervention project analyzes a given dataset on students' performance and develops a machine learning model that will predict the likelihood that a given student will pass, quantifying whether an intervention is necessary. Various algorithms, such as Random Forest, Support Vector Machines, and Naive Bayes will be compared from the standpoint of complexity, runtime, and performance. Given the unbalance in class labels, the F1 score will be utilized as the performance metric. In other words, how well does the model differentiate likely passes from failures.
</p>


<h3>
	<li><a href = "https://github.com/Tsmith5151/Customer-Segments">
	<strong>Customer Segments</strong>
	</a></li></h3>
<p>
In this work, we will take unstructured data, and then attempt to understand the patterns and natural categories that the data fits into. The objective is to analyze this dataset containing data on various customers' annual spending amounts of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.
</p>

<h3>
	<li><a href = "https://github.com/Tsmith5151/Smartcab">
	<strong>Train Smartcab to Drive</strong>
	</a></li></h3>
<p>
Using reinforcement learning to train a smartcab how to drive by implementing Bellman's Q-learning algorithm.
</p>

<h3>
	<li><a href = "https://github.com/Tsmith5151/2016-US-Election-ML">
	<strong>Predicting Primary Winner for POTUS</strong>
	</a></li></h3>
<p>
The objective of this work is to leverage machine-learning techniques (i.e. Decision Trees and Random Forest) to predict whom voters are most likely to elect as the party’s nominee in 2016 Primary Election based on a series of demographics. A large database containing election results for both Democrat and Republican candidates from 28 primary state counties was queried and merged with demographic facts obtained from the United States Census Bureau for corresponding counties. This work examines patterns and trends in how voters cast their ballot given a larger feature space of county demographics spread throughout the United States. In some cases, some states are called with no actual votes tallied. This can come from models, similar to this work, where county-by-county demographics are analyzed for voting trends. The objective is to generate a predictive model and fine tune it such that the algorithm learns from a series of training examples and generalizes to an out of sample testing set that correctly classifies a discrete label, the candidate winner of the respected primary county. 
</p>

<h3>
	<li><a href = "https://github.com/Tsmith5151/Delayed-Flights">
	<strong>Delayed Flights</strong>
	</a></li></h3>
<p>
Exploring and predicting the probability of flights being delayed at airports across the United States given prior flight records. Apache Spark is used in processing the dataset.
</p>

### ***M.S. Research Project***

***Reasearch paper:<a href="/assets/Trace_Smith_MS_Research.pdf"> Download Here</a>***

The objective of this study is to discuss a workflow for evaluating reservoir performance of hydraulic fractured wells in the ultra-tight Tuscaloosa Marine Shale (TMS) through production history matching utilizing Computer Modeling Group’s black oil reservoir simulator. The Tuscaloosa Marine Shale is a highly potential unconventional shale reservoir located near the Gulf Coast in central Louisiana and portions of Southwest Mississippi with an estimated 7 billion barrels of recoverable oil (John et al 1997). Oil and gas companies operating in the play have reported ultimate recoveries estimated to be greater than 800,000 cumulative barrels of oil per well. Published literature and research on the shale formation and reservoir properties are limited, therefore this work is aimed to approximate formation and hydraulic fracture properties for wells drilled in the TMS through production history matching.





